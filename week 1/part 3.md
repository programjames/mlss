# HW 1, Part 3
## By James Camacho
**3.1, kernel PCA**
1. From its definition, $$C = E[x^2] - E[x]^2 = \frac{1}{N}\sum_{i=1}^N\phi(x_i)\phi(x_i)^{T} - \left(\overline{\phi(x)}\right)\left(\overline{\phi(x)}\right)^T,$$ where $\overline{\phi(x)} = \frac{1}{N}\sum_{i=1}^N\phi(x_i)$. An equivalent formula is $$C = E[(x-\overline{\phi(x)})^2]=\frac{1}{N}\sum_{i=1}^N(\phi(x_i)-\overline{\phi(x)})(\phi(x_i)-\overline{\phi(x)})^T.$$ This latter one will be better for the next part.
2. As each column of $C$ is a linear combination of the vectors $(\phi(x_i)-\overline{\phi(x)})$, then $Cv$ can only produce linear combinations of those vectors. So, $\lambda v$ is a linear combination of them, implying $v$ is a linear combination of them, i.e. $$v = \sum_{i=1}^N\alpha_i\left(\phi(x_i)-\overline{\phi(x)}\right).$$
3. We have$$\begin{align*}(\tilde{K}\alpha)_i &= \sum_{j=1}^N\left\langle\phi(x_i)-\overline{\phi(x)},\alpha_j(\phi(x_j)-\overline{\phi(x)})\right\rangle\\&=\left\langle \phi(x_i)-\overline{\phi(x)},v\right\rangle\end{align*}$$by putting the summand inside the inner product. Now,$$\begin{align*}(\tilde{K}(\tilde{K}\alpha))_i &= \sum_{j=1}^N\left\langle\phi(x_i)-\overline{\phi(x)}, (\phi(x_j)-\overline{\phi(x)})\left\langle\phi(x_j)-\overline{\phi(x)}, v\right\rangle\right\rangle\\&=\left\langle\phi(x_i)-\overline{\phi(x)},\sum_{j=1}^N(\phi(x_j)-\overline{\phi(x)})(\phi(x_j)-\overline{\phi(x)})^Tv\right\rangle\\&=\left\langle \phi(x_i)-\overline{\phi(x)}, NCv\right\rangle\\&=\left\langle\phi(x_i)-\overline{\phi(x)}, N\lambda v\right\rangle.\end{align*}$$Pulling out the $N\lambda$ gives the desired.
4. Left multiplying by $\tilde{K}$ gives the desired.
5. Looking at a particular element, we have$$\begin{align*}\tilde{K}_{ij}&= \langle \phi(x_i), \phi(x_j)\rangle - \left\langle\phi(x_i), \overline{\phi(x)}\right\rangle - \left\langle\phi(x_j), \overline{\phi(x)}\right\rangle + \left\langle \overline{\phi(x)}, \overline{\phi(x)}\right\rangle\\&=K_{ij} -(Kee^T)_{ij} - (ee^TK)_{ij} + (ee^TKee^T)_{i,j}\\&=(I-ee^T)K(I-ee^T).\end{align*}$$
6. The square of the norm of $v$ would be $$\begin{align*}\left\langle\sum_{i=1}^N\alpha_i(\phi(x_i)-\overline{\phi(x)}), \sum_{j=1}^N\alpha_j(\phi(x_j)-\overline{\phi(x)})\right\rangle &= \sum_{i=1}^N\alpha_i\sum_{j=1}^N\left\langle\phi(x_i)-\overline{\phi(x)},\phi(x_j)-\overline{\phi(x)}\right\rangle\alpha_j\\&=\alpha^T\tilde{K}\alpha.\end{align*}$$So we need to multiply it by $\frac{1}{\sqrt{\alpha^T\tilde{K}\alpha}}$.
7. Let $V = [v_1\ v_2\ v_3\ \dots\ v_d]$. The new coordinates for $x$ would be $V^{-1}x$. We can calculate $V$ without ever calculating $\phi(x)$ as it only involves inner products, so we can calculate $V^{-1}x$ without ever explicitly calculating $\phi(x)$.