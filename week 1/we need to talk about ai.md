# Notes
## By James Camacho

**Assertions less true in 2020 than in 2022:**
- AGI doesn't exist.
- Eventually we'll have human-level intelligence from AI, but it's going to be awhile, maybe several hundred years.

 **Claims made that might not be true:**
- Self-driving cars must make ethical decisions (no, it's the programmers that make those decisions).
- AI is bad at getting social cues (I'd argue they're better than most humans).
- Machines are accountable, i.e. you can look at them and see what makes them tick (um no, not if they have billions of nodes).

**Discussion questions:**
- Find one claim made in the movie, and try to investigate it further. What did you find?
	- AI accountability. AI is basically a blackbox right now, hard to tell why it makes decisions. Also, who is accountable for the AI? The AI itself is just a machine. Is it the user's fault? The developer's? The environment for giving bad data? One convincing argument is it's the user's fault--they should only use AI to assist, not to make actual decisions, that way if a mistake is made a human can catch it.
- What did you find most compelling about the movie?
	- The problem with consciousness is that almost no one can define what it means. So how do you determine if an AI is conscious?
	- General intelligence could be a good determiner for consciousness.
	- The number of people working on AI safety is so much smaller than working on creating more powerful AI.
	- Most governments should be spending way more money on AI.
- What did you disagree with the most in the movie?
	- The best way to get to general intelligence is to model humans (as humans are the smartest things we know).
	- Is AI bad or good? It gives a bunch of examples of narrow AI for why it's good, but doesn't even talk about how general AI could be good.
- What point do you wish had been made?
	- The huge cost of creating AI's, training data, computing power, energy to run the AI, etc.
- Which of the possible threats from AI that was mentioned seems most important to you? What might convince you to change your mind?
	- Goal alignment not being the same. E.g. it thinks the best way to achieve its goals is to hurt a human. My mind could be changed with a reasonable solution to this, some sort of conscious that overrides goal maximizing.